{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":520,"status":"ok","timestamp":1721386401007,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"RyYrESkDoift"},"outputs":[],"source":["# !sudo apt-get install tesseract-ocr\n","# !pip install tensorflow tensorlayerx numpy easydict tqdm scikit-image pytesseract python-Levenshtein"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1721386401752,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"Ud9IwL-aoifw"},"outputs":[],"source":["import os\n","import numpy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19810,"status":"ok","timestamp":1721386421560,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"RkidcA36oifx","outputId":"b775ce77-d3cd-4e7f-e2ce-6bcddc1e4031"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"AZVdos1hy3FL"},"source":["## Epoch Setting"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":669,"status":"ok","timestamp":1721390237615,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"k8GB8PHgoifx"},"outputs":[],"source":["# Modify it as your own.\n","\n","test_image_path = f'/path/to/test/dataset/folder'\n","\n","model_name = \"your-model-code\"\n","\n","checkpoint_path = f'/path/to/model/folder'\n","\n","epoch_selection = 3000\n","\n","save_dir = f'/path/to/saving/the/testing/result/for/qualitative/testing'\n","ssim_map_path = f\"/path/to/saving/the/ssim/map/for/testing\"\n","\n","log_path = f\"/path/to/your/log/folder\"\n","\n","# Modify this as you need\n","used_weight_g = f\"{checkpoint_path}/g_{epoch_selection}.npz\"\n","\n","if(not os.path.exists(checkpoint_path)):\n","    os.makedirs(checkpoint_path)\n","\n","if(not os.path.exists(log_path)):\n","    os.makedirs(log_path)\n","\n","if(not os.path.exists(ssim_map_path)):\n","    os.makedirs(ssim_map_path)\n","\n","if(not os.path.exists(save_dir)):\n","    os.makedirs(save_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1721386425328,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"mX0uGvagoifx"},"outputs":[],"source":["from datetime import datetime\n","from pathlib import Path\n","from skimage import io, img_as_ubyte\n","\n","\"\"\"\n","Example log:\n","[2023-10-01T00:00][INFO] Some message\n","\n","Put in @see log_path\n","File name is current time session with format of [Implementation - Session Ymd H:i]\n","\"\"\"\n","def write_log(log: str, type: str, namespace: str):\n","    operation = \"x\"\n","    time = datetime.now()\n","    log_location = log_path + \"/\" + time.strftime(\"%Y%m%d\") + f\".{model_name}.test.log\"\n","\n","    if(Path(log_location).is_file()):\n","        operation = \"a\"\n","\n","    fopen = open(log_location, operation)\n","\n","    message = f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}][{type}] [{namespace.upper()}] {log}\\n\"\n","\n","    fopen.write(message)\n","    fopen.close()\n","\n","\"\"\"\n","save_plotter_image_as_file\n","\n","This function helps save the plot image from matplotlib or anything.\n","\n","Should've made this earlier :(\n","\"\"\"\n","def save_plotter_image_as_file(plot):\n","    time = datetime.now()\n","    plot_ubyte =  img_as_ubyte(plot)\n","    io.imsave(ssim_map_path + \"/\" + f\"{time.strftime('%Y-%m-%d %H:%M:%S')}.ssim_map.png\", plot_ubyte)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4142,"status":"ok","timestamp":1721386429459,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"C0ObiBDgoify","outputId":"30a4afe2-301b-465f-c967-b9c0627881e3"},"outputs":[],"source":["from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n","from skimage.color import rgb2gray\n","from tensorlayerx import convert_to_tensor\n","import pytesseract\n","import Levenshtein\n","import re"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1721386429459,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"v5p4QF0Yoifz"},"outputs":[],"source":["\"\"\"\n","hard_round\n","    Converts the float into string first, and then turn it into float by substring\n","    the string value according to the configured decimal_places.\n","\n","    @params float32 number\n","    @params int decimal_place\n","\n","    @returns float32\n","\"\"\"\n","def hard_round(number, decimal_places = 0):\n","    non_coma_value_count = 2\n","\n","    number_in_string: str = str(number)\n","\n","    behind_coma_value_count = len(number_in_string.split(\".\")[1])\n","\n","    if(behind_coma_value_count > 4):\n","        behind_coma_value_count = 4\n","\n","    if(number > 9.9):\n","        non_coma_value_count = len(number_in_string.split(\".\")[0]) + 1\n","\n","    value_length = len(number_in_string)\n","\n","    substring_size = decimal_places + non_coma_value_count # Don't forget the front number 0.\n","\n","    if(value_length < substring_size):\n","        for i in range(0, (substring_size - value_length)):\n","            number_in_string = number_in_string + \"0\"\n","\n","    return float(number_in_string[0:behind_coma_value_count + non_coma_value_count])\n","\n","\"\"\"\n","@since July, 1st 2024\n","MetricManager\n","\n","Metrics turn so bloaty in this experiment. This class intended to clean up testing / evaluator / metrics code.\n","This extremely needed since the functional approach starts turns ugly and complex. This class intended to\n","eliminate the needs of code that needs to run multiple times for example as previous convert_chw_tensor_image_to_standard_image\n","that run in psnr and ssim.\n","\n","Also this design pattern will ease the method call.\n","\n","@example\n","```python\n","metrics = MetricManager(ori_image, gen_image)\n","metrics.ssim().psnr().cer_wer()\n","\n","print(f\"ssim: {metrics.ssim_score} - psnr: {metrics.psnr_score} - cer: {metrics.cer_score}\")\n","```\n","\"\"\"\n","class MetricManager():\n","\n","    \"\"\"\n","    constructor\n","    The constructor helps to reverse Tensor images into NumPy<float32>[].\n","    Replacing the previous convert_chw_tensor_image_to_standard_image\n","\n","    This function doing this procedure as follow:\n","        1. Convert current index's Tensor into NumPy array.\n","        2. Transpose then NumPy array, flip it into 1, 2, 0. This brings back the original HWC array format.\n","        3. Undo the normalization that done earlier in the dataset preprocessing step.\n","\n","    @param @Tensor.float32[] | NumPy<float32> original_images: An array of tensor form of original image array.\n","    @param @Tensor.float32[] generated_images: An array of tensor form of original image array.\n","    \"\"\"\n","    def __init__(self, original_images, generated_images, lowres_images):\n","        self.original_images = original_images\n","        self.generated_images = generated_images\n","        self.lowres_images = lowres_images\n","\n","        self.original_images = numpy.transpose(self.original_images, [0, 2, 3, 1])\n","        self.original_images = (self.original_images * 127.5) + 127.5\n","        self.original_images = self.original_images.astype('uint8')\n","\n","        self.generated_images = numpy.transpose(self.generated_images, [0, 2, 3, 1])\n","        self.generated_images = (self.generated_images * 127.5) + 127.5\n","        self.generated_images = self.generated_images.astype('uint8')\n","\n","        self.lowres_images = numpy.transpose(self.lowres_images, [0, 2, 3, 1])\n","        self.lowres_images = (self.lowres_images * 127.5) + 127.5\n","        self.lowres_images = self.lowres_images.astype('uint8')\n","\n","    \"\"\"\n","    ssim\n","        Stands for Structural Similarity Index Measurement (SSIM), is a used metric\n","        upon training Generator model. This endeavors, eliminate the needs of supervised\n","        corpus layout analysis structure check when training is performed.\n","\n","        This function presume that the original_images's array and generated_images's array\n","        had same shape.\n","\n","        The function will loop for every images in the original_images, getting its length.\n","        For every index, the function is doing this procedure as follow:\n","\n","        1. Convert the NumPy array into Grayscale format\n","        2. Call structural_similarity by skimage\n","        3. Scoring\n","\n","        @requirements: skimage\n","\n","        @return MetricManager\n","    \"\"\"\n","    def ssim(self) -> 'MetricManager':\n","        ssim_scores = []\n","\n","        for i in range (0, len(self.original_images)):\n","            original_image = self.original_images[i]\n","            generated_image = self.generated_images[i]\n","\n","            original_image = rgb2gray(original_image)\n","            generated_image = rgb2gray(generated_image)\n","\n","            ssim_value, ssim_map = structural_similarity(\n","                original_image,\n","                generated_image,\n","                win_size = 3,\n","                full = True,\n","                multi_channel = True,\n","                data_range = 255\n","            )\n","\n","            ssim_scores.append(ssim_value)\n","\n","            ssim_map = ssim_map.astype('uint8')\n","\n","            save_plotter_image_as_file(ssim_map)\n","\n","        self.ssim_scores = hard_round(numpy.mean(ssim_scores), 4)\n","\n","        return self\n","\n","    \"\"\"\n","    psnr\n","        Another metric used in this experimentation is Peak Signal-Noise Ratio (PSNR).\n","        PSNR is more standardized than MSE for scoring things.\n","\n","        Since TensorlayerX's TrainOneStep keep doing Backpropagation using minimization while\n","        PSNR is more tend to be maximize to interpret better result, the result on this function\n","        will be additive inverse, or simply by multiply the PSNR score with -1.\n","\n","        @requirements: skimage\n","\n","        @returns MetricManager\n","    \"\"\"\n","    def psnr(self) -> 'MetricManager':\n","        psnr_scores = []\n","\n","        for i in range (0, len(self.original_images)):\n","            original_image = self.original_images[i]\n","            generated_image = self.generated_images[i]\n","            lowres_image = self.lowres_images[i]\n","\n","            # Init psnr\n","            psnr_score = 0\n","\n","            # Handle precise image\n","            if(numpy.array_equal(original_image, generated_image)):\n","                psnr_score = 99\n","            else:\n","                psnr_score = peak_signal_noise_ratio(\n","                    original_image,\n","                    generated_image,\n","                    data_range = 255\n","                )\n","\n","            # If somehow the psnr turns infinity / non-string value, do an epsilon check.\n","            psnr_scores.append(psnr_score)\n","\n","        self.psnr_scores = hard_round(numpy.mean(psnr_scores), 4)\n","        return self\n","\n","    \"\"\"\"\n","    cer_wer\n","    This metric function stands for Characters Error Rate (CER), and Words Error Rate (WER).\n","    As its name, this function runs a live Tesseract OCR through pytesseract API, to extract\n","    text within image that later be used to count how fixed are the images.\n","\n","    This function working as follow:\n","    1. Do OCR the Image\n","    2. Clean text from escape characters\n","    3. Calculate Levenshtein distance\n","\n","    @requirements: pytesseract, python-Levenshtein\n","\n","    @returns MetricManager\n","    \"\"\"\n","    def cer_wer(self) -> 'MetricManager':\n","        cer_scores = []\n","        wer_scores = []\n","\n","        cer_scores_before_sr = []\n","        wer_scores_before_sr = []\n","\n","        for i in range (0, len(self.original_images)):\n","            original_image = self.original_images[i]\n","            generated_image = self.generated_images[i]\n","            lowres_image = self.lowres_images[i]\n","\n","            original_image = original_image.astype('uint8')\n","            generated_image = generated_image.astype('uint8')\n","            lowres_image = lowres_image.astype('uint8')\n","\n","            original_image_ocr_result = pytesseract.image_to_string(original_image)\n","            generated_image_ocr_result = pytesseract.image_to_string(generated_image)\n","            lowres_image_ocr_result = pytesseract.image_to_string(lowres_image)\n","\n","            # Clean text from escape characters\n","            pattern = r\"\\\\.\"\n","            original_image_ocr_result = re.sub(pattern, \"\", original_image_ocr_result)\n","            generated_image_ocr_result = re.sub(pattern, \"\", generated_image_ocr_result)\n","            lowres_image_ocr_result = re.sub(pattern, \"\", lowres_image_ocr_result)\n","\n","            levenshtein_distance = Levenshtein.distance(original_image_ocr_result, generated_image_ocr_result)\n","            cer = levenshtein_distance / len(original_image_ocr_result)\n","            wer = levenshtein_distance / len(original_image_ocr_result.split(\" \"))\n","\n","            cer_scores.append(cer)\n","            wer_scores.append(wer)\n","\n","            levenshtein_distance_lowres = Levenshtein.distance(original_image_ocr_result, lowres_image_ocr_result)\n","            cer_scores_before_sr.append(levenshtein_distance_lowres / len(original_image_ocr_result))\n","            wer_scores_before_sr.append(levenshtein_distance_lowres / len(original_image_ocr_result.split(\" \")))\n","\n","        self.cer_scores = hard_round(numpy.mean(cer_scores), 4)\n","        self.wer_scores = hard_round(numpy.mean(wer_scores), 4)\n","        self.cer_scores_before_sr = hard_round(numpy.mean(cer_scores_before_sr), 4)\n","        self.wer_scores_before_sr = hard_round(numpy.mean(wer_scores_before_sr), 4)\n","\n","        return self\n","\n","    def save_result(self) -> 'MetricManager':\n","\n","        for i in range (0, len(self.original_images)):\n","            time = datetime.now()\n","            original_image = self.original_images[i]\n","            generated_image = self.generated_images[i]\n","            lowres_image = self.lowres_images[i]\n","\n","            file_folder = f\"{save_dir}/{time.strftime('%Y-%m-%d %H:%M:%S.%f')}\"\n","            os.makedirs(file_folder)\n","            tlx.vision.save_image(original_image, file_name = f'{file_folder}/valid_hr.png', path = save_dir)\n","            tlx.vision.save_image(generated_image, file_name = f'{file_folder}/valid_gen.png', path = save_dir)\n","            tlx.vision.save_image(lowres_image, file_name = f'{file_folder}/valid_lr.png', path = save_dir)\n","\n","        return self"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1721386429459,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"euMEYLsYoif0"},"outputs":[],"source":["from tensorlayerx.dataflow import Dataset, DataLoader\n","from tensorlayerx.vision import load_images\n","from tensorlayerx.vision.transforms import Compose, Normalize, Resize, HWC2CHW\n","import numpy\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1721386429459,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"o19SjA2Noif1"},"outputs":[],"source":["\"\"\"\n","image_transformer_eval\n","    Val and test has data that is uncropped. So, the intension of this\n","    preprocessor is to generate low-resolution (LowRes) image, while the\n","    HighRes image is stay as currently in the dataset. This means that the\n","    transformation process is as follows:\n","\n","    1. Generate LowRes image from HighRes image, by resizing the HighRes\n","    into 4 times smaller.\n","\n","    2. Convert the LowRes image into NumPy<float32>\n","\n","    3. Perform value normalization\n","\n","    4. Perform array transpose from HWC into CHW\n","\"\"\"\n","def image_transformer_eval(image_hr):\n","    # For even division\n","    cropper = Compose([\n","        Resize(size = (1024, 1024))\n","    ])\n","\n","    image_hr = cropper(image_hr)\n","\n","    image_hr_size = [image_hr.shape[0], image_hr.shape[1]]\n","\n","    image_lr = cv2.resize(image_hr, dsize = (image_hr_size[1] // 4, image_hr_size[0] // 4))\n","\n","    normalization = Compose([\n","        Normalize(mean=(127.5), std=(127.5), data_format='HWC'),\n","        HWC2CHW()\n","    ])\n","\n","    return normalization(image_lr), normalization(image_hr)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1721386429459,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"3LiXllXJoif2"},"outputs":[],"source":["# Data Loader Pattern\n","class DatasetLoader(Dataset):\n","\n","    def __init__(self, highres_image, image_transformer = image_transformer_eval):\n","        self.hr_data = highres_image\n","        self.image_transformer = image_transformer\n","\n","    def __getitem__(self, index):\n","        return self.image_transformer(\n","            self.hr_data[index],\n","        )\n","\n","    def __len__(self):\n","        return len(self.hr_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43405,"status":"ok","timestamp":1721386472853,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"cxBRk9n8oif3","outputId":"02cc24c9-e125-4acd-d178-7c7bf02eaee8"},"outputs":[],"source":["# Load data from drive\n","test_hr_image = load_images(path = test_image_path, n_threads = 32)\n","\n","test_hr_image = numpy.array(test_hr_image).astype('uint8')\n","\n","test_dataset = DatasetLoader(test_hr_image, image_transformer = image_transformer_eval)\n","\n","print(f\"Dataset for this batch - Test: {len(test_dataset)}\")\n","\n","test_dataset = DataLoader(test_dataset, batch_size = 16, shuffle = True, drop_last = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1721386472853,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"0SVtUHI0oif3"},"outputs":[],"source":["import tensorlayerx as tlx\n","os.environ['TL_BACKEND'] = 'tensorflow'\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","\n","from tensorlayerx.nn import Module\n","from tensorlayerx.nn import Conv2d, BatchNorm2d, SubpixelConv2d, Sequential\n","from tensorlayerx import ReLU"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1721386472854,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"hgucAC_Yoif3"},"outputs":[],"source":["class ResidualBlock(Module):\n","\n","    def __init__(self, resblock_number: int = 1):\n","        super(ResidualBlock, self).__init__()\n","\n","        self.conv1 = Conv2d(\n","            out_channels=128, kernel_size=(3, 3), stride=(1, 1),\n","            act=ReLU, padding='SAME',\n","            data_format='channels_first', b_init=None, name = f\"conv2d_resblock_{resblock_number}_1\"\n","        )\n","\n","        self.bn1 = BatchNorm2d(\n","            num_features=128, act=None,\n","            data_format='channels_first', name = f\"batchnorm2d_resblock_{resblock_number}_1\"\n","        )\n","\n","        self.conv2 = Conv2d(\n","            out_channels=128, kernel_size=(3, 3), stride=(1, 1),\n","            act=ReLU, padding='SAME',\n","            data_format='channels_first', b_init=None, name = f\"conv2d_resblock_{resblock_number}_2\"\n","        )\n","\n","        self.bn2 = BatchNorm2d(\n","            num_features=128, act=None,\n","            data_format='channels_first', name = f\"batchnorm2d_resblock_{resblock_number}_2\"\n","        )\n","\n","    def forward(self, x):\n","        z = self.conv1(x)\n","        z = self.bn1(z)\n","        z = self.conv2(z)\n","        z = self.bn2(z)\n","        x = x + z\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1721386472854,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"yJy7cX2hoif4"},"outputs":[],"source":["class Generator(Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        self.conv1 = Conv2d(\n","            out_channels=128, kernel_size=(3, 3), stride=(1, 1),\n","            act=ReLU,\n","            data_format='channels_first', name = \"conv2d_G_1\"\n","        )\n","\n","        self.residual_block = self.make_layer()\n","\n","        self.conv2 = Conv2d(\n","            out_channels=128, kernel_size=(3, 3), stride=(1, 1),\n","            act=ReLU,\n","            data_format='channels_first', b_init=None, name = \"conv2d_G_2\"\n","        )\n","\n","        self.bn1 = BatchNorm2d(\n","            num_features=128,\n","            data_format='channels_first', name = \"batchnorm2d_G_1\"\n","        )\n","\n","        self.conv3 = Conv2d(\n","            out_channels=512, kernel_size=(3, 3), stride=(1, 1),\n","            data_format='channels_first', name = \"conv2d_G_3\"\n","        )\n","\n","        self.subpixelconv1 = SubpixelConv2d(\n","            scale=2, act=ReLU,\n","            data_format='channels_first', name = \"subpixelconv2d_G_1\"\n","        )\n","\n","        self.conv4 = Conv2d(\n","            out_channels=512, kernel_size=(3, 3), stride=(1, 1),\n","            data_format='channels_first', name = \"conv2d_G_4\"\n","        )\n","\n","        self.subpixelconv2 = SubpixelConv2d(\n","            scale=2, act=ReLU,\n","            data_format='channels_first', name = \"subpixelconv2d_G_2\"\n","        )\n","\n","        self.output = Conv2d(\n","            out_channels = 3, kernel_size=(1, 1), stride=(1, 1),\n","            act=tlx.Tanh,\n","            data_format='channels_first', name = \"conv2d_G_output\"\n","        )\n","\n","    def make_layer(self):\n","        layer_list = []\n","\n","        for i in range(16):\n","            layer_list.append(ResidualBlock(i))\n","\n","        return Sequential(layer_list)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        temp = x\n","        x = self.residual_block(x)\n","        x = self.conv2(x)\n","        x = self.bn1(x)\n","        x = x + temp\n","        x = self.conv3(x)\n","        x = self.subpixelconv1(x)\n","        x = self.conv4(x)\n","        x = self.subpixelconv2(x)\n","        x = self.output(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"SeW4YcPRyyrx"},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2564,"status":"ok","timestamp":1721390241796,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"Y0QdIPZmoif4","outputId":"38227a8a-30ab-43f9-d8e3-49b97567f43c"},"outputs":[],"source":["generator_model = Generator()\n","generator_model.init_build(tlx.nn.Input(shape=(16, 3, 56, 56)))\n","generator_model.load_weights(used_weight_g, format = \"npz_dict\", skip = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1721386480659,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"EfsFG6VToif4"},"outputs":[],"source":["from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"k6lqgx73y0xY"},"source":["## Test Run"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":539514,"status":"ok","timestamp":1721390781307,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"wv0bRsYioif5","outputId":"7c11eaf7-1c51-4bd0-c0af-9bdb23866d3d"},"outputs":[],"source":["generator_model.set_eval()\n","\n","test_ssim, test_psnr, test_cer, test_wer, test_cer_non_sr, test_wer_non_sr = [], [], [], [], [], []\n","\n","for step, (lr_patch, hr_patch) in enumerate(tqdm(test_dataset)):\n","    gen_image = generator_model(lr_patch)\n","    metrics = MetricManager(hr_patch, gen_image, lr_patch)\n","    metrics.ssim().psnr().cer_wer().save_result()\n","    test_ssim.append(float(metrics.ssim_scores))\n","    test_psnr.append(float(metrics.psnr_scores))\n","    test_cer.append(float(metrics.cer_scores))\n","    test_wer.append(float(metrics.wer_scores))\n","    test_cer_non_sr.append(float(metrics.cer_scores_before_sr))\n","    test_wer_non_sr.append(float(metrics.wer_scores_before_sr))\n","\n","test_ssim = hard_round(numpy.mean(test_ssim), 4)\n","test_psnr = hard_round(numpy.mean(test_psnr), 4)\n","test_cer = hard_round(numpy.mean(test_cer), 4)\n","test_wer = hard_round(numpy.mean(test_wer), 4)\n","test_cer_non_sr = hard_round(numpy.mean(test_cer_non_sr), 4)\n","test_wer_non_sr = hard_round(numpy.mean(test_wer_non_sr), 4)\n","\n","message = f\"\"\"\n","MODEL {model_name} testing result:\n","\n","model file: {used_weight_g}\n","SSIM: {test_ssim}\n","PSNR: {test_psnr}\n","CER [Before SR -> After SR] : {test_cer_non_sr} -> {test_cer}\n","WER [Before SR -> After SR]  : {test_wer_non_sr} -> {test_wer}\n","\"\"\"\n","\n","message"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
