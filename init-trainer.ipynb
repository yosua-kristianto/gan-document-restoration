{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"eSe7NHUHsmi7"},"outputs":[],"source":["# !pip install tensorflow tensorlayerx numpy easydict tqdm scikit-image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XOTrE736smi_"},"outputs":[],"source":["import os\n","import numpy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2807,"status":"ok","timestamp":1720873549202,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"QR2Uiq-msmi_","outputId":"4154e996-db0c-487a-ee8f-02e456cd91b8"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PtAENGrEsmjA"},"outputs":[],"source":["train_image_path = f'/path/to/train/folder'\n","val_image_path = f'/path/to/val/folder'\n","\n","model_name = \"define-your-own-model-code-name-here\"\n","\n","checkpoint_path = f'/path/to/your/model/training/backup/folder'\n","\n","# existing_model = f\"/path/to/npz/file/for/transfer-learning/model.npz\"\n","existing_model = None\n","\n","log_path = f\"/path/to/your/log/folder\"\n","\n","if(not os.path.exists(checkpoint_path)):\n","    os.makedirs(checkpoint_path)\n","\n","if(not os.path.exists(log_path)):\n","    os.makedirs(log_path)"]},{"cell_type":"markdown","metadata":{"id":"8v-dmckdsmjA"},"source":["# Helper Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9lph0c4CsmjC"},"outputs":[],"source":["import requests\n","from datetime import datetime\n","from pathlib import Path\n","\n","\"\"\"\n","Example log:\n","[2023-10-01T00:00][INFO] Some message\n","\n","Put in log_path\n","File name is current time session with format of [Implementation - Session Ymd H:i]\n","\"\"\"\n","def write_log(log: str, type: str, namespace: str):\n","    operation = \"x\"\n","    time = datetime.now()\n","    log_location = log_path + \"/\" + time.strftime(\"%Y%m%d\") + \".init_training.log\"\n","\n","    if(Path(log_location).is_file()):\n","        operation = \"a\"\n","\n","    fopen = open(log_location, operation)\n","\n","    message = f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}][{type}] [{namespace.upper()}] {log}\\n\"\n","\n","    fopen.write(message)\n","    fopen.close()"]},{"cell_type":"markdown","metadata":{"id":"p1MiNZnRsmjC"},"source":["# Custom Metrics Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u-pPhwfIsmjD"},"outputs":[],"source":["from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n","from skimage.color import rgb2gray\n","from tensorlayerx import convert_to_tensor\n","import re"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9W5rWvwesmjD"},"outputs":[],"source":["\"\"\"\n","hard_round\n","    Converts the float into string first, and then turn it into float by substring\n","    the string value according to the configured decimal_places.\n","\n","    @params float32 number\n","    @params int decimal_place\n","\n","    @returns float32\n","\"\"\"\n","def hard_round(number, decimal_places = 0):\n","    non_coma_value_count = 2\n","\n","    number_in_string: str = str(number)\n","\n","    behind_coma_value_count = len(number_in_string.split(\".\")[1])\n","\n","    if(behind_coma_value_count > 4):\n","        behind_coma_value_count = 4\n","\n","    if(number > 9.9):\n","        non_coma_value_count = len(number_in_string.split(\".\")[0]) + 1\n","\n","    value_length = len(number_in_string)\n","\n","    substring_size = decimal_places + non_coma_value_count # Don't forget the front number 0.\n","\n","    if(value_length < substring_size):\n","        for i in range(0, (substring_size - value_length)):\n","            number_in_string = number_in_string + \"0\"\n","\n","    return float(number_in_string[0:behind_coma_value_count + non_coma_value_count])\n","\n","\"\"\"\n","@since July, 1st 2024\n","MetricManager\n","\n","Metrics turn so bloaty in this experiment. This class intended to clean up testing / evaluator / metrics code.\n","This extremely needed since the functional approach starts turns ugly and complex. This class intended to\n","eliminate the needs of code that needs to run multiple times for example as previous convert_chw_tensor_image_to_standard_image\n","that run in psnr and ssim.\n","\n","Also this design pattern will ease the method call.\n","\n","@example\n","```python\n","metrics = MetricManager(ori_image, gen_image)\n","metrics.ssim().psnr().cer_wer()\n","\n","print(f\"ssim: {metrics.ssim_score} - psnr: {metrics.psnr_score} - cer: {metrics.cer_score}\")\n","```\n","\"\"\"\n","class MetricManager():\n","\n","    \"\"\"\n","    constructor\n","    The constructor helps to reverse Tensor images into NumPy<float32>[].\n","    Replacing the previous convert_chw_tensor_image_to_standard_image\n","\n","    This function doing this procedure as follow:\n","        1. Convert current index's Tensor into NumPy array.\n","        2. Transpose then NumPy array, flip it into 1, 2, 0. This brings back the original HWC array format.\n","        3. Undo the normalization that done earlier in the dataset preprocessing step.\n","\n","    @param @Tensor.float32[] | NumPy<float32> original_images: An array of tensor form of original image array.\n","    @param @Tensor.float32[] generated_images: An array of tensor form of original image array.\n","    \"\"\"\n","    def __init__(self, original_images, generated_images):\n","        self.original_images = original_images\n","        self.generated_images = generated_images\n","\n","        self.original_images = self.original_images.numpy().astype('uint8')\n","        self.original_images = numpy.transpose(self.original_images, [0, 2, 3, 1])\n","        self.original_images = (self.original_images * 127.5) + 127.5\n","\n","        self.generated_images = self.generated_images.numpy().astype('uint8')\n","        self.generated_images = numpy.transpose(self.generated_images, [0, 2, 3, 1])\n","        self.generated_images = (self.generated_images * 127.5) + 127.5\n","\n","    \"\"\"\n","    ssim\n","        Stands for Structural Similarity Index Measurement (SSIM), is a used metric\n","        upon training Generator model. This endeavors, eliminate the needs of qualitative\n","        corpus layout analysis structure check when training is performed.\n","\n","        This function presume that the original_images's array and generated_images's array\n","        had same shape.\n","\n","        The function will loop for every images in the original_images, getting its length.\n","        For every index, the function is doing this procedure as follow:\n","\n","        1. Convert the NumPy array into Grayscale format\n","        2. Call structural_similarity by skimage\n","        3. Scoring\n","\n","        @requirements: skimage\n","\n","        @return MetricManager\n","    \"\"\"\n","    def ssim(self) -> 'MetricManager':\n","        ssim_scores = []\n","\n","        for i in range (0, len(self.original_images)):\n","            original_image = self.original_images[i]\n","            generated_image = self.generated_images[i]\n","\n","            original_image = rgb2gray(original_image)\n","            generated_image = rgb2gray(generated_image)\n","\n","            ssim_value, ssim_map = structural_similarity(\n","                original_image,\n","                generated_image,\n","                win_size = 3,\n","                full = True,\n","                multi_channel = True,\n","                data_range = 255\n","            )\n","\n","            ssim_scores.append(ssim_value)\n","\n","        self.ssim_scores = hard_round(numpy.mean(ssim_scores), 4)\n","\n","        return self\n","\n","    \"\"\"\n","    psnr\n","        Another metric used in this experimentation is Peak Signal-Noise Ratio (PSNR).\n","        PSNR is more standardized than MSE for scoring things.\n","\n","        @requirements: skimage\n","\n","        @returns MetricManager\n","    \"\"\"\n","    def psnr(self) -> 'MetricManager':\n","        psnr_scores = []\n","\n","        for i in range (0, len(self.original_images)):\n","            original_image = self.original_images[i]\n","            generated_image = self.generated_images[i]\n","\n","            # Init psnr\n","            psnr_score = 0\n","\n","            # Handle precise image\n","            if(numpy.array_equal(original_image, generated_image)):\n","                psnr_score = 99\n","            else:\n","                psnr_score = peak_signal_noise_ratio(\n","                    original_image,\n","                    generated_image,\n","                    data_range = 255\n","                )\n","\n","                # Handle infinity.\n","                if(psnr_score > 99):\n","                    psnr_score = 99\n","\n","            psnr_scores.append(psnr_score)\n","\n","        self.psnr_scores = hard_round(numpy.mean(psnr_scores), 4)\n","        return self\n","\n","    \"\"\"\"\n","    cer_wer\n","    This metric function stands for Characters Error Rate (CER), and Words Error Rate (WER).\n","    As its name, this function runs a live Tesseract OCR through pytesseract API, to extract\n","    text within image that later be used to count how fixed are the images.\n","\n","    This function working as follow:\n","    1. Do OCR the Image\n","    2. Clean text from escape characters\n","    3. Calculate Levenshtein distance\n","\n","    @requirements: pytesseract, python-Levenshtein\n","\n","    @returns MetricManager\n","    \"\"\"\n","    def cer_wer(self) -> 'MetricManager':\n","        cer_scores = []\n","        wer_scores = []\n","\n","        for i in range (0, len(self.original_images)):\n","            original_image = self.original_images[i]\n","            generated_image = self.generated_images[i]\n","\n","            original_image = original_image.astype('uint8')\n","            generated_image = generated_image.astype('uint8')\n","\n","            original_image_ocr_result = pytesseract.image_to_string(original_image)\n","            generated_image_ocr_result = pytesseract.image_to_string(generated_image)\n","\n","            # Clean text from escape characters\n","            pattern = r\"\\\\.\"\n","            original_image_ocr_result = re.sub(pattern, \"\", original_image_ocr_result)\n","            generated_image_ocr_result = re.sub(pattern, \"\", generated_image_ocr_result)\n","\n","            levenshtein_distance = Levenshtein.distance(original_image_ocr_result, generated_image_ocr_result)\n","            cer = levenshtein_distance / len(original_image_ocr_result)\n","            wer = levenshtein_distance / len(original_image_ocr_result.split(\" \"))\n","\n","            cer_scores.append(cer)\n","            wer_scores.append(wer)\n","\n","        self.cer_scores = hard_round(numpy.mean(cer_scores), 4)\n","        self.wer_scores = hard_round(numpy.mean(wer_scores), 4)\n","\n","        return self"]},{"cell_type":"markdown","metadata":{"id":"c7FqwMjqsmjE"},"source":["# Pre-Processing and Augmentation Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G6nbcLArsmjF"},"outputs":[],"source":["from tensorlayerx.dataflow import Dataset, DataLoader\n","from tensorlayerx.vision import load_images\n","from tensorlayerx.vision.transforms import Compose, RandomCrop, Normalize, Resize, HWC2CHW"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0WcogSHWsmjF"},"outputs":[],"source":["\"\"\"\n","image_transformer_random_crop\n","    This function helps to randomly crop a part of image, by taking\n","    224 x 224 pixel worth image. The result, then being resized into\n","    56 x 56 pixel to generate its own low-resolution image.\n","\n","    This function returns the transposed array version\n","    (CHW -> Channel Height Width) of low-resolution and original cropped\n","    image with value normalized into 0 to 1.\n","\n","    @param @NumPy<uint8>[] image_hr\n","\n","    @return\n","        (Numpy<int8>[], Numpy<int8>[])\n","\"\"\"\n","def image_transformer_random_crop(image_hr):\n","    cropper = Compose([\n","        RandomCrop(size=(224, 224))\n","    ])\n","\n","    image_hr = cropper(image_hr)\n","    image_lr = Resize(size = (56, 56))(image_hr)\n","\n","    normalization = Compose([\n","        Normalize(mean=(127.5), std=(127.5), data_format='HWC'),\n","        HWC2CHW()\n","    ])\n","\n","    return normalization(image_lr), normalization(image_hr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tiSkAlOusmjH"},"outputs":[],"source":["# Data Loader Pattern\n","class DatasetLoader(Dataset):\n","\n","    def __init__(self, highres_image, image_transformer = image_transformer_random_crop):\n","        self.hr_data = highres_image\n","        self.image_transformer = image_transformer\n","\n","    def __getitem__(self, index):\n","        return self.image_transformer(\n","            self.hr_data[index],\n","        )\n","\n","    def __len__(self):\n","        return len(self.hr_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":299427,"status":"ok","timestamp":1720873848626,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"hq-yn3aXsmjH","outputId":"efbefb2e-a0c4-4a3f-8a46-bad0ec5794a2"},"outputs":[],"source":["# Load data from drive\n","train_hr_image = load_images(path = train_image_path, n_threads = 16)\n","val_hr_image = load_images(path = val_image_path, n_threads = 10)\n","\n","# Convert those data into numpy array instead of list.\n","train_hr_image = numpy.array(train_hr_image).astype('uint8')\n","val_hr_image = numpy.array(val_hr_image).astype('uint8')\n","\n","# Data Loading and Transformation\n","train_dataset = DatasetLoader(train_hr_image, image_transformer = image_transformer_random_crop)\n","val_dataset = DatasetLoader(val_hr_image, image_transformer = image_transformer_random_crop)\n","print(f\"Dataset for this batch - Train: {len(train_dataset)} - Val: {len(val_dataset)}\")\n","\n","# Data Loader\n","train_dataset = DataLoader(train_dataset, batch_size = 16, shuffle = True, drop_last = True)\n","val_dataset = DataLoader(val_dataset, batch_size = 16, shuffle = True, drop_last = True)"]},{"cell_type":"markdown","metadata":{"id":"DwGUpDEdsmjI"},"source":["# Model part"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4z7tx6lfsmjI"},"outputs":[],"source":["import tensorlayerx as tlx\n","os.environ['TL_BACKEND'] = 'tensorflow'\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","\n","from tensorlayerx.nn import Module\n","from tensorlayerx.nn import Conv2d, BatchNorm2d, Elementwise, SubpixelConv2d, Flatten, Sequential, BatchNorm\n","from tensorlayerx.nn import Linear\n","from tensorlayerx import LeakyReLU, ReLU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZUXVI_NksmjJ"},"outputs":[],"source":["class ResidualBlock(Module):\n","\n","    def __init__(self, resblock_number: int = 1):\n","        super(ResidualBlock, self).__init__()\n","\n","        self.conv1 = Conv2d(\n","            out_channels=128, kernel_size=(3, 3), stride=(1, 1),\n","            act=ReLU, padding='SAME',\n","            data_format='channels_first', b_init=None, name = f\"conv2d_resblock_{resblock_number}_1\"\n","        )\n","\n","        self.bn1 = BatchNorm2d(\n","            num_features=128, act=None,\n","            data_format='channels_first', name = f\"batchnorm2d_resblock_{resblock_number}_1\"\n","        )\n","\n","        self.conv2 = Conv2d(\n","            out_channels=128, kernel_size=(3, 3), stride=(1, 1),\n","            act=ReLU, padding='SAME',\n","            data_format='channels_first', b_init=None, name = f\"conv2d_resblock_{resblock_number}_2\"\n","        )\n","\n","        self.bn2 = BatchNorm2d(\n","            num_features=128, act=None,\n","            data_format='channels_first', name = f\"batchnorm2d_resblock_{resblock_number}_2\"\n","        )\n","\n","    def forward(self, x):\n","        z = self.conv1(x)\n","        z = self.bn1(z)\n","        z = self.conv2(z)\n","        z = self.bn2(z)\n","        x = x + z\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b_MR5U-asmjJ"},"outputs":[],"source":["class Generator(Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        self.conv1 = Conv2d(\n","            out_channels=128, kernel_size=(3, 3), stride=(1, 1),\n","            act=ReLU,\n","            data_format='channels_first', name = \"conv2d_G_1\"\n","        )\n","\n","        self.residual_block = self.make_layer()\n","\n","        self.conv2 = Conv2d(\n","            out_channels=128, kernel_size=(3, 3), stride=(1, 1),\n","            act=ReLU,\n","            data_format='channels_first', b_init=None, name = \"conv2d_G_2\"\n","        )\n","\n","        self.bn1 = BatchNorm2d(\n","            num_features=128,\n","            data_format='channels_first', name = \"batchnorm2d_G_1\"\n","        )\n","\n","        self.conv3 = Conv2d(\n","            out_channels=512, kernel_size=(3, 3), stride=(1, 1),\n","            data_format='channels_first', name = \"conv2d_G_3\"\n","        )\n","\n","        self.subpixelconv1 = SubpixelConv2d(\n","            scale=2, act=ReLU,\n","            data_format='channels_first', name = \"subpixelconv2d_G_1\"\n","        )\n","\n","        self.conv4 = Conv2d(\n","            out_channels=512, kernel_size=(3, 3), stride=(1, 1),\n","            data_format='channels_first', name = \"conv2d_G_4\"\n","        )\n","\n","        self.subpixelconv2 = SubpixelConv2d(\n","            scale=2, act=ReLU,\n","            data_format='channels_first', name = \"subpixelconv2d_G_2\"\n","        )\n","\n","        self.output = Conv2d(\n","            out_channels = 3, kernel_size=(1, 1), stride=(1, 1),\n","            act=tlx.Tanh,\n","            data_format='channels_first', name = \"conv2d_G_output\"\n","        )\n","\n","\n","    def make_layer(self):\n","        layer_list = []\n","\n","        for i in range(16):\n","            layer_list.append(ResidualBlock(i))\n","\n","        return Sequential(layer_list)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        temp = x\n","        x = self.residual_block(x)\n","        x = self.conv2(x)\n","        x = self.bn1(x)\n","        x = x + temp\n","        x = self.conv3(x)\n","        x = self.subpixelconv1(x)\n","        x = self.conv4(x)\n","        x = self.subpixelconv2(x)\n","        x = self.output(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"XZHCI1zRsmjJ"},"source":["# Training the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-5LYh_aCsmjK"},"outputs":[],"source":["from tqdm import tqdm\n","from tensorlayerx.model import TrainOneStep\n","from tensorlayerx.nn import Module\n","from tensorlayerx.losses import mean_squared_error\n","\n","tlx.set_device('GPU')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":547,"status":"ok","timestamp":1720873927772,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"VYfSrDVssmjK","outputId":"7a325b9b-9def-47b3-ea35-97146c98aa02"},"outputs":[],"source":["# Hyperparameters\n","batch_size = 16\n","epoch_total = 300\n","decay = tlx.optimizers.lr.StepDecay(\n","    learning_rate = 1e-4,\n","    step_size = 200,\n","    gamma = 1e-1,\n","    last_epoch = -1,\n","    verbose = True\n",")\n","optimizer = tlx.optimizers.Adam(decay, 5e-2)\n","\n","generator_model = Generator()\n","generator_model.init_build(tlx.nn.Input(shape=(batch_size, 3, 56, 56)))\n","g_weights = generator_model.trainable_weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qbWNaO-nsmjK"},"outputs":[],"source":["class NetWithLoss_init(Module):\n","    def __init__(self, generator_model, loss_fn):\n","        super(NetWithLoss_init, self).__init__()\n","        self.net = generator_model\n","        self.loss_fn = loss_fn\n","\n","    def forward(self, lr, hr):\n","        out = self.net(lr)\n","        loss = self.loss_fn(out, hr)\n","        return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I5QUMCDpsmjK"},"outputs":[],"source":["G_with_loss = NetWithLoss_init(generator_model = generator_model, loss_fn = mean_squared_error)\n","trainer = TrainOneStep(\n","    G_with_loss,\n","    optimizer = optimizer,\n","    train_weights = g_weights\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9411803,"status":"ok","timestamp":1720883662879,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"4yyy91FnsmjL","outputId":"e4edbbbf-125e-48e2-ee90-1a631dc1773c"},"outputs":[],"source":["# Evaluation record for Generator training\n","progress_train_init_G_epoch = []\n","\n","progress_train_init_G_loss = []\n","progress_train_init_G_ssim = []\n","progress_train_init_G_psnr = []\n","\n","progress_val_init_G_loss = []\n","progress_val_init_G_ssim = []\n","progress_val_init_G_psnr = []\n","\n","for epoch in range(epoch_total):\n","    print(f\"Epoch {epoch + 1} / {epoch_total}\", end = \" \")\n","\n","    generator_model.set_train()\n","\n","    train_loss, train_ssim, train_psnr, train_cer, train_wer = [], [], [], [], []\n","\n","    for step, (lr_patch, hr_patch) in enumerate(tqdm(train_dataset)):\n","        # Loss\n","        loss = trainer(lr_patch, hr_patch)\n","\n","        train_loss.append(loss)\n","\n","        # Metrics\n","        metrics = MetricManager(hr_patch, generator_model(lr_patch))\n","        metrics.ssim().psnr()\n","\n","        train_ssim.append(float(metrics.ssim_scores))\n","        train_psnr.append(float(metrics.psnr_scores))\n","\n","    train_loss = hard_round(numpy.mean(train_loss), 4)\n","    train_ssim = hard_round(numpy.mean(train_ssim), 4)\n","    train_psnr = hard_round(numpy.mean(train_psnr), 4)\n","\n","    progress_train_init_G_epoch.append(epoch + 1)\n","    progress_train_init_G_loss.append(train_loss)\n","    progress_train_init_G_ssim.append(train_ssim)\n","    progress_train_init_G_psnr.append(train_psnr)\n","\n","    generator_model.set_eval()\n","    val_loss, val_ssim, val_psnr, val_cer, val_wer = [], [], [], [], []\n","\n","    for step, (lr_patch, hr_patch) in enumerate(val_dataset):\n","        loss = G_with_loss(lr_patch, hr_patch)\n","\n","        val_loss.append(loss)\n","\n","        # Metrics\n","        metrics = MetricManager(hr_patch, generator_model(lr_patch))\n","        metrics.ssim().psnr()\n","\n","        val_ssim.append(float(metrics.ssim_scores))\n","        val_psnr.append(float(metrics.psnr_scores))\n","\n","    val_loss = hard_round(numpy.mean(val_loss), 4)\n","    val_ssim = hard_round(numpy.mean(val_ssim), 4)\n","    val_psnr = hard_round(numpy.mean(val_psnr), 4)\n","\n","    progress_val_init_G_loss.append(val_loss)\n","    progress_val_init_G_ssim.append(val_ssim)\n","    progress_val_init_G_psnr.append(val_psnr)\n","\n","    train_progress_text = f\"Epoch [{epoch+1} / {epoch_total}] - train loss: {train_loss} - train metrics [ssim | pnsr]: [{train_ssim} | {train_psnr}]\"\n","    val_progress_text = f\" - val loss: {val_loss} - val metrics [ssim | pnsr]: [{val_ssim} | {val_psnr}]\"\n","\n","    print(train_progress_text)\n","    print(f\"\\t\\t\\t {val_progress_text}\")\n","    print(\"\\n\\n\")\n","\n","    decay.step()\n","\n","    write_log(f\"{train_progress_text} {val_progress_text}\", \"INFO\", \"INIT TRAINING\")\n","\n","    generator_model.save_weights(os.path.join(checkpoint_path, f'g_init_{epoch + 1}.npz'), format='npz_dict')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1720883662883,"user":{"displayName":"Yosua Kristianto","userId":"13772103754468982237"},"user_tz":-420},"id":"z8eaAAC4IJSF","outputId":"a439e683-40b2-43ad-b148-d74a2f335fd7"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(20, 15))\n","\n","# Plot training loss\n","plt.subplot2grid((3, 2), (0, 0))\n","plt.plot(progress_train_init_G_epoch, progress_train_init_G_loss, label='Training MSE Loss', marker='o')\n","plt.plot(progress_train_init_G_epoch, progress_val_init_G_loss, label='Validation MSE Loss', marker='o')\n","plt.title('Generator Initial Training Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('MSE')\n","plt.legend()\n","\n","# Plot training SSIM\n","plt.subplot2grid((3, 2), (0, 1))\n","plt.plot(progress_train_init_G_epoch, progress_train_init_G_ssim, label='Training SSIM', marker='o')\n","plt.plot(progress_train_init_G_epoch, progress_val_init_G_ssim, label='Validation SSIM', marker='o')\n","plt.title('Generator Initial Training SSIM Score')\n","plt.xlabel('Epoch')\n","plt.ylabel('SSIM')\n","plt.legend()\n","\n","# Plot training PSNR\n","plt.subplot2grid((3, 2), (1, 0))\n","plt.plot(progress_train_init_G_epoch, progress_train_init_G_psnr, label='Training PSNR', marker='o')\n","plt.plot(progress_train_init_G_epoch, progress_val_init_G_psnr, label='Validation PSNR', marker='o')\n","plt.title('Generator Initial Training PSNR Score')\n","plt.xlabel('Epoch')\n","plt.ylabel('PSNR')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
