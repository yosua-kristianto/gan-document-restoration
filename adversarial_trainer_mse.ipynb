{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HThQHDRFsey"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow tensorlayerx numpy easydict tqdm scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NFpgMu0Fse2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4pNrfGbFse3",
        "outputId": "f5affe48-eca0-4798-d3b8-f279aa74f4a0"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Feel free to not use any of this and modify the code.\n",
        "json_file_path = \"/path/to/optional/config.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ciqo0clDFse4"
      },
      "outputs": [],
      "source": [
        "# Load configuration JSON\n",
        "with open(json_file_path, \"r\") as fopen:\n",
        "    json_config = json.load(fopen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwTyFuuGFse5"
      },
      "outputs": [],
      "source": [
        "train_image_path = f'/path/to/train/folder'\n",
        "val_image_path = f'/path/to/val/folder'\n",
        "\n",
        "model_name = \"define-your-own-model-code-name-here\"\n",
        "\n",
        "checkpoint_path = f'/path/to/your/model/training/backup/folder'\n",
        "\n",
        "log_path = f\"/path/to/your/log/folder\"\n",
        "\n",
        "if(not os.path.exists(checkpoint_path)):\n",
        "    os.makedirs(checkpoint_path)\n",
        "\n",
        "if(not os.path.exists(log_path)):\n",
        "    os.makedirs(log_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehalHTGuFse6"
      },
      "outputs": [],
      "source": [
        "used_weight_g = json_config[\"g_weight\"]\n",
        "used_weight_d = json_config[\"d_weight\"]\n",
        "\n",
        "training_iteration = json_config[\"batch\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoYNlnqH6g8U",
        "outputId": "7606916b-0078-4f75-fa26-95bf15043d6d"
      },
      "outputs": [],
      "source": [
        "used_weight_g, used_weight_d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB2tC0tyFse7"
      },
      "source": [
        "# VGG\n",
        "As per this was pushed, the vgg model weight npz file is no longer available. So you can download it here:\n",
        "\n",
        "https://1drv.ms/f/s!An-BtXH8gRhe1PZbC-IJUX0wA4o-Lw?e=wvrCmL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1711_fQFse9"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/MyDrive/Colab Notebooks/Thesis/SRGAN/vgg_setup/vgg.py\" ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_3y0-2xFse_",
        "outputId": "5ca5c356-ecff-4e70-b958-a0fa9377e21a"
      },
      "outputs": [],
      "source": [
        "import vgg\n",
        "\n",
        "VGG = vgg.VGG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuMIy_RbFsfA"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJcfnqCCFsfA"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "\"\"\"\n",
        "Example log:\n",
        "[2023-10-01T00:00][INFO] Some message\n",
        "\n",
        "Put in @see log_path\n",
        "File name is current time session with format of [Implementation - Session Ymd H:i]\n",
        "\"\"\"\n",
        "def write_log(log: str, type: str, namespace: str):\n",
        "    operation = \"x\"\n",
        "    time = datetime.now()\n",
        "    log_location = log_path + \"/\" + time.strftime(\"%Y%m%d\") + \".adv_mse_perceptual.log\"\n",
        "\n",
        "    if(Path(log_location).is_file()):\n",
        "        operation = \"a\"\n",
        "\n",
        "    fopen = open(log_location, operation)\n",
        "\n",
        "    message = f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}][{type}] [{namespace.upper()}] {log}\\n\"\n",
        "\n",
        "    fopen.write(message)\n",
        "    fopen.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZTb5eADFsfB"
      },
      "source": [
        "# Custom Metrics Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4mwm3o5FsfC"
      },
      "outputs": [],
      "source": [
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
        "from skimage.color import rgb2gray\n",
        "from tensorlayerx import convert_to_tensor\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxkK3CPuFsfC"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "hard_round\n",
        "    Converts the float into string first, and then turn it into float by substring\n",
        "    the string value according to the configured decimal_places.\n",
        "\n",
        "    @params float32 number\n",
        "    @params int decimal_place\n",
        "\n",
        "    @returns float32\n",
        "\"\"\"\n",
        "def hard_round(number, decimal_places = 0):\n",
        "    non_coma_value_count = 2\n",
        "\n",
        "    number_in_string: str = str(number)\n",
        "\n",
        "    behind_coma_value_count = len(number_in_string.split(\".\")[1])\n",
        "\n",
        "    if(behind_coma_value_count > 4):\n",
        "        behind_coma_value_count = 4\n",
        "\n",
        "    if(number > 9.9):\n",
        "        non_coma_value_count = len(number_in_string.split(\".\")[0]) + 1\n",
        "\n",
        "    value_length = len(number_in_string)\n",
        "\n",
        "    substring_size = decimal_places + non_coma_value_count # Don't forget the front number 0.\n",
        "\n",
        "    if(value_length < substring_size):\n",
        "        for i in range(0, (substring_size - value_length)):\n",
        "            number_in_string = number_in_string + \"0\"\n",
        "\n",
        "    return float(number_in_string[0:behind_coma_value_count + non_coma_value_count])\n",
        "\n",
        "\"\"\"\n",
        "@since July, 1st 2024\n",
        "MetricManager\n",
        "\n",
        "Metrics turn so bloaty in this experiment. This class intended to clean up testing / evaluator / metrics code.\n",
        "This extremely needed since the functional approach starts turns ugly and complex. This class intended to\n",
        "eliminate the needs of code that needs to run multiple times for example as previous convert_chw_tensor_image_to_standard_image\n",
        "that run in psnr and ssim.\n",
        "\n",
        "Also this design pattern will ease the method call.\n",
        "\n",
        "@example\n",
        "```python\n",
        "metrics = MetricManager(ori_image, gen_image)\n",
        "metrics.ssim().psnr().cer_wer()\n",
        "\n",
        "print(f\"ssim: {metrics.ssim_score} - psnr: {metrics.psnr_score} - cer: {metrics.cer_score}\")\n",
        "```\n",
        "\"\"\"\n",
        "class MetricManager():\n",
        "\n",
        "    \"\"\"\n",
        "    constructor\n",
        "    The constructor helps to reverse Tensor images into NumPy<float32>[].\n",
        "    Replacing the previous convert_chw_tensor_image_to_standard_image\n",
        "\n",
        "    This function doing this procedure as follow:\n",
        "        1. Convert current index's Tensor into NumPy array.\n",
        "        2. Transpose then NumPy array, flip it into 1, 2, 0. This brings back the original HWC array format.\n",
        "        3. Undo the normalization that done earlier in the dataset preprocessing step.\n",
        "\n",
        "    @param @Tensor.float32[] | NumPy<float32> original_images: An array of tensor form of original image array.\n",
        "    @param @Tensor.float32[] generated_images: An array of tensor form of original image array.\n",
        "    \"\"\"\n",
        "    def __init__(self, original_images, generated_images):\n",
        "        self.original_images = original_images\n",
        "        self.generated_images = generated_images\n",
        "\n",
        "        self.original_images = self.original_images.numpy().astype('uint8')\n",
        "        self.original_images = numpy.transpose(self.original_images, [0, 2, 3, 1])\n",
        "        self.original_images = (self.original_images * 127.5) + 127.5\n",
        "\n",
        "        self.generated_images = self.generated_images.numpy().astype('uint8')\n",
        "        self.generated_images = numpy.transpose(self.generated_images, [0, 2, 3, 1])\n",
        "        self.generated_images = (self.generated_images * 127.5) + 127.5\n",
        "\n",
        "    \"\"\"\n",
        "    ssim\n",
        "        Stands for Structural Similarity Index Measurement (SSIM), is a used metric\n",
        "        upon training Generator model. This endeavors, eliminate the needs of qualitative\n",
        "        corpus layout analysis structure check when training is performed.\n",
        "\n",
        "        This function presume that the original_images's array and generated_images's array\n",
        "        had same shape.\n",
        "\n",
        "        The function will loop for every images in the original_images, getting its length.\n",
        "        For every index, the function is doing this procedure as follow:\n",
        "\n",
        "        1. Convert the NumPy array into Grayscale format\n",
        "        2. Call structural_similarity by skimage\n",
        "        3. Scoring\n",
        "\n",
        "        @requirements: skimage\n",
        "\n",
        "        @return MetricManager\n",
        "    \"\"\"\n",
        "    def ssim(self) -> 'MetricManager':\n",
        "        ssim_scores = []\n",
        "\n",
        "        for i in range (0, len(self.original_images)):\n",
        "            original_image = self.original_images[i]\n",
        "            generated_image = self.generated_images[i]\n",
        "\n",
        "            original_image = rgb2gray(original_image)\n",
        "            generated_image = rgb2gray(generated_image)\n",
        "\n",
        "            ssim_value, ssim_map = structural_similarity(\n",
        "                original_image,\n",
        "                generated_image,\n",
        "                win_size = 3,\n",
        "                full = True,\n",
        "                multi_channel = True,\n",
        "                data_range = 255\n",
        "            )\n",
        "\n",
        "            ssim_scores.append(ssim_value)\n",
        "\n",
        "        self.ssim_scores = hard_round(numpy.mean(ssim_scores), 4)\n",
        "\n",
        "        return self\n",
        "\n",
        "    \"\"\"\n",
        "    psnr\n",
        "        Another metric used in this experimentation is Peak Signal-Noise Ratio (PSNR).\n",
        "        PSNR is more standardized than MSE for scoring things.\n",
        "\n",
        "        @requirements: skimage\n",
        "\n",
        "        @returns MetricManager\n",
        "    \"\"\"\n",
        "    def psnr(self) -> 'MetricManager':\n",
        "        psnr_scores = []\n",
        "\n",
        "        for i in range (0, len(self.original_images)):\n",
        "            original_image = self.original_images[i]\n",
        "            generated_image = self.generated_images[i]\n",
        "\n",
        "            # Init psnr\n",
        "            psnr_score = 0\n",
        "\n",
        "            # Handle precise image\n",
        "            if(numpy.array_equal(original_image, generated_image)):\n",
        "                psnr_score = 99\n",
        "            else:\n",
        "                psnr_score = peak_signal_noise_ratio(\n",
        "                    original_image,\n",
        "                    generated_image,\n",
        "                    data_range = 255\n",
        "                )\n",
        "\n",
        "                # Handle infinity.\n",
        "                if(psnr_score > 99):\n",
        "                    psnr_score = 99\n",
        "\n",
        "            psnr_scores.append(psnr_score)\n",
        "\n",
        "        self.psnr_scores = hard_round(numpy.mean(psnr_scores), 4)\n",
        "        return self\n",
        "\n",
        "    \"\"\"\"\n",
        "    cer_wer\n",
        "    This metric function stands for Characters Error Rate (CER), and Words Error Rate (WER).\n",
        "    As its name, this function runs a live Tesseract OCR through pytesseract API, to extract\n",
        "    text within image that later be used to count how fixed are the images.\n",
        "\n",
        "    This function working as follow:\n",
        "    1. Do OCR the Image\n",
        "    2. Clean text from escape characters\n",
        "    3. Calculate Levenshtein distance\n",
        "\n",
        "    @requirements: pytesseract, python-Levenshtein\n",
        "\n",
        "    @returns MetricManager\n",
        "    \"\"\"\n",
        "    def cer_wer(self) -> 'MetricManager':\n",
        "        cer_scores = []\n",
        "        wer_scores = []\n",
        "\n",
        "        for i in range (0, len(self.original_images)):\n",
        "            original_image = self.original_images[i]\n",
        "            generated_image = self.generated_images[i]\n",
        "\n",
        "            original_image = original_image.astype('uint8')\n",
        "            generated_image = generated_image.astype('uint8')\n",
        "\n",
        "            original_image_ocr_result = pytesseract.image_to_string(original_image)\n",
        "            generated_image_ocr_result = pytesseract.image_to_string(generated_image)\n",
        "\n",
        "            # Clean text from escape characters\n",
        "            pattern = r\"\\\\.\"\n",
        "            original_image_ocr_result = re.sub(pattern, \"\", original_image_ocr_result)\n",
        "            generated_image_ocr_result = re.sub(pattern, \"\", generated_image_ocr_result)\n",
        "\n",
        "            levenshtein_distance = Levenshtein.distance(original_image_ocr_result, generated_image_ocr_result)\n",
        "            cer = levenshtein_distance / len(original_image_ocr_result)\n",
        "            wer = levenshtein_distance / len(original_image_ocr_result.split(\" \"))\n",
        "\n",
        "            cer_scores.append(cer)\n",
        "            wer_scores.append(wer)\n",
        "\n",
        "        self.cer_scores = hard_round(numpy.mean(cer_scores), 4)\n",
        "        self.wer_scores = hard_round(numpy.mean(wer_scores), 4)\n",
        "\n",
        "        return self"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRlm4iuLFsfF"
      },
      "source": [
        "# Pre-Processing and Augmentation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W24PD8TJFsfF"
      },
      "outputs": [],
      "source": [
        "from tensorlayerx.dataflow import Dataset, DataLoader\n",
        "from tensorlayerx.vision import load_images\n",
        "from tensorlayerx.vision.transforms import Compose, RandomCrop, Normalize, Resize, HWC2CHW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UELmc_--FsfG"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "image_transformer_random_crop\n",
        "    This function helps to randomly crop a part of image, by taking\n",
        "    224 x 224 pixel worth image. The result, then being resized into\n",
        "    56 x 56 pixel to generate its own low-resolution image.\n",
        "\n",
        "    This function returns the transposed array version\n",
        "    (CHW -> Channel Height Width) of low-resolution and original cropped\n",
        "    image with value normalized into 0 to 1.\n",
        "\n",
        "    @param @NumPy<uint8>[] image_hr\n",
        "\n",
        "    @return\n",
        "        (Numpy<int8>[], Numpy<int8>[])\n",
        "\"\"\"\n",
        "def image_transformer_random_crop(image_hr):\n",
        "    cropper = Compose([\n",
        "        RandomCrop(size=(224, 224))\n",
        "    ])\n",
        "\n",
        "    image_hr = cropper(image_hr)\n",
        "    image_lr = Resize(size = (56, 56))(image_hr)\n",
        "\n",
        "    normalization = Compose([\n",
        "        Normalize(mean=(127.5), std=(127.5), data_format='HWC'),\n",
        "        HWC2CHW()\n",
        "    ])\n",
        "\n",
        "    return normalization(image_lr), normalization(image_hr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dazc_CEJFsfG"
      },
      "outputs": [],
      "source": [
        "# Data Loader Pattern\n",
        "class DatasetLoader(Dataset):\n",
        "\n",
        "    def __init__(self, highres_image, image_transformer = image_transformer_random_crop):\n",
        "        self.hr_data = highres_image\n",
        "        self.image_transformer = image_transformer\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.image_transformer(\n",
        "            self.hr_data[index],\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.hr_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WQOJGWcFsfH",
        "outputId": "04fe9b42-e8ff-4a26-8675-9c04c6fb94c6"
      },
      "outputs": [],
      "source": [
        "# Load data from drive\n",
        "train_hr_image = load_images(path = train_image_path, n_threads = 16)\n",
        "val_hr_image = load_images(path = val_image_path, n_threads = 10)\n",
        "\n",
        "# Convert those data into numpy array instead of list.\n",
        "train_hr_image = numpy.array(train_hr_image).astype('uint8')\n",
        "val_hr_image = numpy.array(val_hr_image).astype('uint8')\n",
        "\n",
        "# Data Loading and Transformation\n",
        "train_dataset = DatasetLoader(train_hr_image, image_transformer = image_transformer_random_crop)\n",
        "val_dataset = DatasetLoader(val_hr_image, image_transformer = image_transformer_random_crop)\n",
        "print(f\"Dataset for this batch - Train: {len(train_dataset)} - Val: {len(val_dataset)}\")\n",
        "\n",
        "# Data Loader\n",
        "train_dataset = DataLoader(train_dataset, batch_size = 16, shuffle = True, drop_last = True)\n",
        "val_dataset = DataLoader(val_dataset, batch_size = 16, shuffle = True, drop_last = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5M1eHj-FsfH"
      },
      "source": [
        "# Model part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91-k8MwKFsfH"
      },
      "outputs": [],
      "source": [
        "import tensorlayerx as tlx\n",
        "os.environ['TL_BACKEND'] = 'tensorflow'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "from tensorlayerx.nn import Module\n",
        "from tensorlayerx.nn import Conv2d, BatchNorm2d, SubpixelConv2d, Flatten, Sequential, BatchNorm\n",
        "from tensorlayerx.nn import Linear\n",
        "from tensorlayerx import LeakyReLU, ReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKXBdS0pFsfI"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(Module):\n",
        "\n",
        "    def __init__(self, resblock_number: int = 1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = Conv2d(\n",
        "            out_channels=128, kernel_size=(3, 3), stride=(1, 1),\n",
        "            act=ReLU, padding='SAME',\n",
        "            data_format='channels_first', b_init=None, name = f\"conv2d_resblock_{resblock_number}_1\"\n",
        "        )\n",
        "\n",
        "        self.bn1 = BatchNorm2d(\n",
        "            num_features=128, act=None,\n",
        "            data_format='channels_first', name = f\"batchnorm2d_resblock_{resblock_number}_1\"\n",
        "        )\n",
        "\n",
        "        self.conv2 = Conv2d(\n",
        "            out_channels=128, kernel_size=(3, 3), stride=(1, 1),\n",
        "            act=ReLU, padding='SAME',\n",
        "            data_format='channels_first', b_init=None, name = f\"conv2d_resblock_{resblock_number}_2\"\n",
        "        )\n",
        "\n",
        "        self.bn2 = BatchNorm2d(\n",
        "            num_features=128, act=None,\n",
        "            data_format='channels_first', name = f\"batchnorm2d_resblock_{resblock_number}_2\"\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.conv1(x)\n",
        "        z = self.bn1(z)\n",
        "        z = self.conv2(z)\n",
        "        z = self.bn2(z)\n",
        "        x = x + z\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2m6NV3CFsfI"
      },
      "outputs": [],
      "source": [
        "class Generator(Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.conv1 = Conv2d(\n",
        "            out_channels=128, kernel_size=(3, 3), stride=(1, 1),\n",
        "            act=ReLU,\n",
        "            data_format='channels_first', name = \"conv2d_G_1\"\n",
        "        )\n",
        "\n",
        "        self.residual_block = self.make_layer()\n",
        "\n",
        "        self.conv2 = Conv2d(\n",
        "            out_channels=128, kernel_size=(3, 3), stride=(1, 1),\n",
        "            act=ReLU,\n",
        "            data_format='channels_first', b_init=None, name = \"conv2d_G_2\"\n",
        "        )\n",
        "\n",
        "        self.bn1 = BatchNorm2d(\n",
        "            num_features=128,\n",
        "            data_format='channels_first', name = \"batchnorm2d_G_1\"\n",
        "        )\n",
        "\n",
        "        self.conv3 = Conv2d(\n",
        "            out_channels=512, kernel_size=(3, 3), stride=(1, 1),\n",
        "            data_format='channels_first', name = \"conv2d_G_3\"\n",
        "        )\n",
        "\n",
        "        self.subpixelconv1 = SubpixelConv2d(\n",
        "            scale=2, act=ReLU,\n",
        "            data_format='channels_first', name = \"subpixelconv2d_G_1\"\n",
        "        )\n",
        "\n",
        "        self.conv4 = Conv2d(\n",
        "            out_channels=512, kernel_size=(3, 3), stride=(1, 1),\n",
        "            data_format='channels_first', name = \"conv2d_G_4\"\n",
        "        )\n",
        "\n",
        "        self.subpixelconv2 = SubpixelConv2d(\n",
        "            scale=2, act=ReLU,\n",
        "            data_format='channels_first', name = \"subpixelconv2d_G_2\"\n",
        "        )\n",
        "\n",
        "        self.output = Conv2d(\n",
        "            out_channels = 3, kernel_size=(1, 1), stride=(1, 1),\n",
        "            act=tlx.Tanh,\n",
        "            data_format='channels_first', name = \"conv2d_G_output\"\n",
        "        )\n",
        "\n",
        "    def make_layer(self):\n",
        "        layer_list = []\n",
        "\n",
        "        for i in range(16):\n",
        "            layer_list.append(ResidualBlock(i))\n",
        "\n",
        "        return Sequential(layer_list)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        temp = x\n",
        "        x = self.residual_block(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn1(x)\n",
        "        x = x + temp\n",
        "        x = self.conv3(x)\n",
        "        x = self.subpixelconv1(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.subpixelconv2(x)\n",
        "        x = self.output(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MltdQsvFsfJ"
      },
      "outputs": [],
      "source": [
        "W_init = tlx.initializers.TruncatedNormal(stddev=0.02)\n",
        "G_init = tlx.initializers.TruncatedNormal(mean=1.0, stddev=0.02)\n",
        "\n",
        "class Discriminator(Module):\n",
        "    def __init__(self, default_multiplier = 128):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv1 = Conv2d(\n",
        "            out_channels = default_multiplier * 1, kernel_size = (3, 3),\n",
        "            act=LeakyReLU, W_init=W_init,\n",
        "            data_format='channels_first', name = \"D_conv2d_1_1\"\n",
        "        )\n",
        "\n",
        "        self.conv2 = Conv2d(\n",
        "            out_channels = default_multiplier * 1, kernel_size=(3, 3),\n",
        "            act=LeakyReLU, W_init=W_init,\n",
        "            data_format='channels_first', b_init=None, name = \"D_conv2d_1_2\"\n",
        "        )\n",
        "\n",
        "        self.bn1 = BatchNorm(\n",
        "            gamma_init = G_init, data_format = \"channels_first\",\n",
        "            name = \"D_bn_1\"\n",
        "        )\n",
        "\n",
        "        self.conv3 = Conv2d(\n",
        "            out_channels = default_multiplier * 2, kernel_size=(3, 3), stride = (2, 2),\n",
        "            act=LeakyReLU, W_init=W_init,\n",
        "            data_format='channels_first', b_init=None, name = \"D_conv2d_2_1\"\n",
        "        )\n",
        "\n",
        "        self.bn2 = BatchNorm(\n",
        "            gamma_init = G_init, data_format = \"channels_first\",\n",
        "            name = \"D_bn_2\"\n",
        "        )\n",
        "\n",
        "        self.conv4 = Conv2d(\n",
        "            out_channels = default_multiplier * 4, kernel_size=(5, 5), stride = (2, 2),\n",
        "            act=LeakyReLU, W_init=W_init,\n",
        "            data_format='channels_first', b_init=None, name = \"D_conv2d_2_2\"\n",
        "        )\n",
        "\n",
        "        self.bn3 = BatchNorm(\n",
        "            gamma_init = G_init, data_format = \"channels_first\",\n",
        "            name = \"D_bn_3\"\n",
        "        )\n",
        "\n",
        "        self.conv5 = Conv2d(\n",
        "            out_channels = default_multiplier * 8, kernel_size=(7, 7), stride = (2, 2), act=LeakyReLU, W_init=W_init,\n",
        "            data_format='channels_first', b_init=None, name = \"D_conv2d_3_1\"\n",
        "        )\n",
        "\n",
        "        self.bn4 = BatchNorm(\n",
        "            gamma_init = G_init, data_format = \"channels_first\",\n",
        "            name = \"D_bn_4\"\n",
        "        )\n",
        "\n",
        "        self.conv6 = Conv2d(\n",
        "            out_channels = default_multiplier * 16, kernel_size=(1, 1), act=LeakyReLU, W_init=W_init,\n",
        "            data_format='channels_first', b_init=None, name = \"D_conv2d_3_2\"\n",
        "        )\n",
        "\n",
        "        self.bn5 = BatchNorm(\n",
        "            gamma_init = G_init, data_format = \"channels_first\",\n",
        "            name = \"D_bn_5\"\n",
        "        )\n",
        "\n",
        "        self.conv7 = Conv2d(\n",
        "            out_channels = default_multiplier * 8, kernel_size=(3, 3), stride = (2, 2), act=LeakyReLU, W_init=W_init,\n",
        "            data_format='channels_first', b_init=None, name = \"D_conv2d_4_1\"\n",
        "        )\n",
        "\n",
        "        self.bn6 = BatchNorm(\n",
        "            gamma_init = G_init, data_format = \"channels_first\",\n",
        "            name = \"D_bn_6\"\n",
        "        )\n",
        "\n",
        "        self.conv8 = Conv2d(\n",
        "            out_channels = default_multiplier * 1, kernel_size=(1, 1), stride = (1, 1), act=LeakyReLU, W_init=W_init,\n",
        "            data_format='channels_first', b_init=None, name = \"D_conv2d_4_2\"\n",
        "        )\n",
        "\n",
        "        self.bn7 = BatchNorm(\n",
        "            gamma_init = G_init, data_format = \"channels_first\",\n",
        "            name = \"D_bn_7\"\n",
        "        )\n",
        "\n",
        "        self.flat = Flatten(name = \"flat\")\n",
        "\n",
        "        self.dense = Linear(out_features=1, W_init=W_init, name = \"output_D\", act = tlx.Sigmoid)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn1(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.bn4(x)\n",
        "\n",
        "        x = self.conv6(x)\n",
        "        x = self.bn5(x)\n",
        "\n",
        "        x = self.conv7(x)\n",
        "        x = self.bn6(x)\n",
        "\n",
        "        x = self.conv8(x)\n",
        "        x = self.bn7(x)\n",
        "\n",
        "        x = self.flat(x)\n",
        "        x = self.dense(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BS3QxpuFsfK"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsxjZelKFsfK",
        "outputId": "21a9d289-2db8-48ce-e1ef-75dbbe4af9c0"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from tensorlayerx.model import TrainOneStep\n",
        "from tensorlayerx.nn import Module\n",
        "from tensorlayerx.losses import mean_squared_error\n",
        "\n",
        "tlx.set_device('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TktG0xERFsfK",
        "outputId": "e3915487-4bf2-4bbb-c819-43189c3902d0"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "batch_size = 16\n",
        "epoch_total = 500\n",
        "current_epoch = training_iteration * epoch_total\n",
        "expected_last_epoch = current_epoch + epoch_total\n",
        "\n",
        "decay = tlx.optimizers.lr.StepDecay(\n",
        "    learning_rate = 1e-3,\n",
        "    step_size = 2400,\n",
        "    gamma = 1e-1,\n",
        "    last_epoch = -1,\n",
        "    verbose = True\n",
        ")\n",
        "\n",
        "generator_model = Generator()\n",
        "discriminator_model = Discriminator()\n",
        "\n",
        "generator_model.init_build(tlx.nn.Input(shape=(batch_size, 3, 56, 56)))\n",
        "discriminator_model.init_build(tlx.nn.Input(shape=(16, 3, 224, 224)))\n",
        "\n",
        "if(used_weight_g):\n",
        "    generator_model.load_weights(used_weight_g, format = \"npz_dict\", skip = False)\n",
        "\n",
        "if(used_weight_d):\n",
        "    discriminator_model.load_weights(used_weight_d, format = \"npz_dict\", skip = False)\n",
        "\n",
        "g_weights = generator_model.trainable_weights\n",
        "d_weights = discriminator_model.trainable_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKKajRqnFsfL"
      },
      "source": [
        "# Training Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Afs4DOfyFsfL"
      },
      "outputs": [],
      "source": [
        "class NetWithLoss_Adv_D(Module):\n",
        "    def __init__(self, D_net, G_net, loss_fn):\n",
        "        super(NetWithLoss_Adv_D, self).__init__()\n",
        "        self.D_net = D_net\n",
        "        self.G_net = G_net\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def forward(self, lr, hr):\n",
        "        fake_patchs = self.G_net(lr)\n",
        "        logits_fake = self.D_net(fake_patchs)\n",
        "        logits_real = self.D_net(hr)\n",
        "\n",
        "        d_loss1 = self.loss_fn(logits_real, tlx.ones_like(logits_real))\n",
        "        d_loss1 = tlx.ops.reduce_mean(d_loss1)\n",
        "\n",
        "        d_loss2 = self.loss_fn(logits_fake, tlx.zeros_like(logits_fake))\n",
        "        d_loss2 = tlx.ops.reduce_mean(d_loss2)\n",
        "\n",
        "        d_loss = d_loss1 + d_loss2\n",
        "        return d_loss\n",
        "\n",
        "class NetWithLoss_Adv_G(Module):\n",
        "    def __init__(self, D_net, G_net, vgg, loss_fn1, loss_fn2):\n",
        "        super(NetWithLoss_Adv_G, self).__init__()\n",
        "        self.D_net = D_net\n",
        "        self.G_net = G_net\n",
        "        self.vgg = vgg\n",
        "        self.loss_fn1 = loss_fn1\n",
        "        self.loss_fn2 = loss_fn2\n",
        "\n",
        "    def forward(self, lr, hr):\n",
        "        # Generated image\n",
        "        generated_image_tensor = self.G_net(lr)\n",
        "\n",
        "        # Determinator judgement\n",
        "        discriminator_logits_for_generated_image = self.D_net(generated_image_tensor)\n",
        "\n",
        "        feature_fake = self.vgg((generated_image_tensor + 1) / 2.)\n",
        "        feature_real = self.vgg((hr + 1) / 2.)\n",
        "\n",
        "        # Adversarial Loss\n",
        "        g_gan_loss = self.loss_fn1(discriminator_logits_for_generated_image, tlx.ones_like(discriminator_logits_for_generated_image))\n",
        "        g_gan_loss = tlx.ops.reduce_mean(g_gan_loss)\n",
        "\n",
        "        # Content Loss\n",
        "        mse_loss = self.loss_fn2(generated_image_tensor, hr)\n",
        "        vgg_loss = 2e-6 * self.loss_fn2(feature_fake, feature_real)\n",
        "\n",
        "        mse_loss = (mse_loss)\n",
        "\n",
        "        g_loss = mse_loss + vgg_loss + g_gan_loss\n",
        "        return g_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WytWFos9FsfL",
        "outputId": "7af2b8d4-a2a7-4943-9438-250833b61ccd"
      },
      "outputs": [],
      "source": [
        "# adversarial learning (G, D)\n",
        "g_optimizer = tlx.optimizers.Adam(decay, 1e-2)\n",
        "d_optimizer = tlx.optimizers.Adam(decay, 1e-2)\n",
        "\n",
        "net_with_loss_D = NetWithLoss_Adv_D(\n",
        "    D_net = discriminator_model,\n",
        "    G_net = generator_model,\n",
        "    loss_fn = tlx.losses.sigmoid_cross_entropy\n",
        ")\n",
        "\n",
        "net_with_loss_G = NetWithLoss_Adv_G(\n",
        "    D_net = discriminator_model,\n",
        "    G_net = generator_model,\n",
        "    vgg = VGG,\n",
        "    loss_fn1 = tlx.losses.sigmoid_cross_entropy,\n",
        "    loss_fn2 = tlx.losses.mean_squared_error\n",
        ")\n",
        "\n",
        "trainforG = TrainOneStep(net_with_loss_G, optimizer = g_optimizer, train_weights = g_weights)\n",
        "trainforD = TrainOneStep(net_with_loss_D, optimizer = d_optimizer, train_weights = d_weights)\n",
        "\n",
        "n_step_epoch = round(len(train_dataset) // batch_size)\n",
        "\n",
        "progress_train_adv_epoch = []\n",
        "progress_train_adv_G_loss = []\n",
        "progress_train_adv_D_loss = []\n",
        "\n",
        "progress_train_adv_G_ssim = []\n",
        "progress_train_adv_G_psnr = []\n",
        "\n",
        "progress_val_adv_G_loss = []\n",
        "progress_val_adv_G_ssim = []\n",
        "progress_val_adv_G_psnr = []\n",
        "\n",
        "discriminator_model.set_train()\n",
        "\n",
        "for epoch in range(current_epoch, expected_last_epoch):\n",
        "    print(f\"Epoch [{epoch + 1} / {expected_last_epoch}] - \", end = \" \")\n",
        "\n",
        "    generator_model.set_train()\n",
        "\n",
        "    train_G_loss, train_G_ssim, train_G_psnr, train_D_loss = [], [], [], []\n",
        "\n",
        "    for step, (lr_patch, hr_patch) in enumerate(tqdm(train_dataset)):\n",
        "        train_loss_g = trainforG(lr_patch, hr_patch)\n",
        "        train_loss_d = trainforD(lr_patch, hr_patch)\n",
        "        train_G_loss.append(float(train_loss_g))\n",
        "        train_D_loss.append(float(train_loss_d))\n",
        "\n",
        "        # Metrics\n",
        "        metrics = MetricManager(hr_patch, generator_model(lr_patch))\n",
        "        metrics.ssim().psnr()\n",
        "\n",
        "        train_G_ssim.append(float(metrics.ssim_scores))\n",
        "        train_G_psnr.append(float(metrics.psnr_scores))\n",
        "\n",
        "    train_D_loss = hard_round(numpy.mean(train_D_loss), 4)\n",
        "    train_G_loss = hard_round(numpy.mean(train_G_loss), 4)\n",
        "\n",
        "    train_G_ssim = hard_round(numpy.mean(train_G_ssim), 4)\n",
        "    train_G_psnr = hard_round(numpy.mean(train_G_psnr), 4)\n",
        "\n",
        "    progress_train_adv_epoch.append(epoch + 1)\n",
        "    progress_train_adv_G_loss.append(train_G_loss)\n",
        "    progress_train_adv_D_loss.append(train_D_loss)\n",
        "\n",
        "    progress_train_adv_G_ssim.append(train_G_ssim)\n",
        "    progress_train_adv_G_psnr.append(train_G_psnr)\n",
        "\n",
        "    generator_model.set_eval()\n",
        "\n",
        "    val_G_loss, val_G_ssim, val_G_psnr = [], [], []\n",
        "\n",
        "    for step, (lr_patch, hr_patch) in enumerate(val_dataset):\n",
        "        val_loss_g = net_with_loss_G(lr_patch, hr_patch)\n",
        "        val_G_loss.append(float(val_loss_g))\n",
        "\n",
        "        # Metrics\n",
        "        metrics = MetricManager(hr_patch, generator_model(lr_patch))\n",
        "        metrics.ssim().psnr()\n",
        "\n",
        "        val_G_ssim.append(float(metrics.ssim_scores))\n",
        "        val_G_psnr.append(float(metrics.psnr_scores))\n",
        "\n",
        "    val_G_loss = hard_round(numpy.mean(val_G_loss), 4)\n",
        "    val_G_ssim = hard_round(numpy.mean(val_G_ssim), 4)\n",
        "    val_G_psnr = hard_round(numpy.mean(val_G_psnr), 4)\n",
        "\n",
        "    progress_val_adv_G_loss.append(val_G_loss)\n",
        "    progress_val_adv_G_ssim.append(val_G_ssim)\n",
        "    progress_val_adv_G_psnr.append(val_G_psnr)\n",
        "\n",
        "    train_info: str = f\"Epoch [{epoch+1} / {expected_last_epoch}] - train G loss: {train_G_loss} - train D loss: {train_D_loss} - train G metrics [ssim | pnsr]: [{train_G_ssim} | {train_G_psnr}]\"\n",
        "    val_info: str = f\" - val G loss: {val_G_loss} - val G metrics [ssim | pnsr]: [{val_G_ssim} | {val_G_psnr}]\"\n",
        "\n",
        "    print(train_info)\n",
        "    print(f\"\\t\\t\\t {val_info}\")\n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "    write_log(f\"{train_info}{val_info}\", \"INFO\", \"GENERATIVE ADVERSARIAL TRAINING\")\n",
        "\n",
        "    # dynamic learning rate update\n",
        "    decay.step()\n",
        "\n",
        "    # if (epoch != 0) and (epoch + 1 % 10 == 0):\n",
        "    generator_model.save_weights(os.path.join(checkpoint_path, f'g_{epoch + 1}.npz'), format='npz_dict')\n",
        "    discriminator_model.save_weights(os.path.join(checkpoint_path, f'd_{epoch + 1}.npz'), format='npz_dict')\n",
        "\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4seA48q5FsfM"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzo1LueQFsfM"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bE2AAevFFsfN"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 15))\n",
        "\n",
        "# Adversarial Learning Loss\n",
        "plt.subplot2grid((3, 2), (0, 0))\n",
        "plt.plot(progress_train_adv_epoch, progress_train_adv_G_loss, label='Training Perceptual Loss', marker='o')\n",
        "plt.plot(progress_train_adv_epoch, progress_val_adv_G_loss, label='Validation Perceptual Loss', marker='o')\n",
        "plt.title('Adversarial Learning Perceptual Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Adversarial Learning SSIM\n",
        "plt.subplot2grid((3, 2), (0, 1))\n",
        "plt.plot(progress_train_adv_epoch, progress_train_adv_G_ssim, label='Training SSIM', marker='o')\n",
        "plt.plot(progress_train_adv_epoch, progress_val_adv_G_ssim, label='Validation SSIM', marker='o')\n",
        "plt.title('Adversarial Learning SSIM')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('SSIM')\n",
        "plt.legend()\n",
        "\n",
        "# Adversarial Learning PSNR\n",
        "plt.subplot2grid((3, 2), (1, 0))\n",
        "plt.plot(progress_train_adv_epoch, progress_train_adv_G_psnr, label='Training PSNR', marker='o')\n",
        "plt.plot(progress_train_adv_epoch, progress_val_adv_G_psnr, label='Validation PSNR', marker='o')\n",
        "plt.title('Adversarial Learning PSNR')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('PSNR')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuEPx3XmjGNO"
      },
      "outputs": [],
      "source": [
        "bio = BytesIO()\n",
        "plt.savefig(bio, format='png', bbox_inches='tight')\n",
        "bio.seek(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AisiNltkFsfN"
      },
      "outputs": [],
      "source": [
        "# Getting error of float32 cannot be deserialized (?) JavaScript is weird\n",
        "progress_train_adv_G_ssim = numpy.float64(progress_train_adv_G_ssim)\n",
        "progress_train_adv_G_loss = numpy.float64(progress_train_adv_G_loss)\n",
        "progress_train_adv_D_loss = numpy.float64(progress_train_adv_D_loss)\n",
        "progress_train_adv_G_psnr = numpy.float64(progress_train_adv_G_psnr)\n",
        "\n",
        "progress_val_adv_G_loss = numpy.float64(progress_val_adv_G_loss)\n",
        "progress_val_adv_G_ssim = numpy.float64(progress_val_adv_G_ssim)\n",
        "progress_val_adv_G_psnr = numpy.float64(progress_val_adv_G_psnr)\n",
        "\n",
        "# Save Adversarial training result\n",
        "report_adv_train = {}\n",
        "report_adv_val = {}\n",
        "report_discriminator_loss = {}\n",
        "\n",
        "for i in range(0, epoch_total):\n",
        "    key = f\"epoch-{progress_train_adv_epoch[i]}\"\n",
        "    report_adv_train[key] = {\n",
        "        \"loss\": progress_train_adv_G_loss[i],\n",
        "        \"ssim\": progress_train_adv_G_ssim[i],\n",
        "        \"psnr\": progress_train_adv_G_psnr[i],\n",
        "    }\n",
        "\n",
        "    report_adv_val[key] = {\n",
        "        \"loss\": progress_val_adv_G_loss[i],\n",
        "        \"ssim\": progress_val_adv_G_ssim[i],\n",
        "        \"psnr\": progress_val_adv_G_psnr[i],\n",
        "    }\n",
        "\n",
        "best_psnr_epoch = int(numpy.argmax(progress_val_adv_G_psnr) + 1) + current_epoch\n",
        "best_ssim_epoch = int(numpy.argmax(progress_val_adv_G_ssim) + 1) + current_epoch\n",
        "\n",
        "json_config[\"Generator\"].append({\n",
        "    \"batch\": json_config[\"batch\"],\n",
        "    \"training\": report_adv_train,\n",
        "    \"validation\": report_adv_val,\n",
        "    \"best_epoch\": {\n",
        "        \"highest-psnr-based\": best_psnr_epoch,\n",
        "        \"highest-ssim-based\": best_ssim_epoch\n",
        "    }\n",
        "})\n",
        "\n",
        "json_config[\"batch\"] = json_config[\"batch\"] + 1\n",
        "\n",
        "with open(json_file_path, \"w\") as file:\n",
        "    json.dump(json_config, file, indent = 4, default = lambda x: \"Invalid Value\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeDYMVwOFsfO"
      },
      "outputs": [],
      "source": [
        "json_config"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
